{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Kopia_notatnika_Czesc2_2022_Odkrywanie_modeli_BPMN_3 (1).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "---\n",
    "show-code: False\n",
    "title: Zwizualizuj diagram BPMN\n",
    "authors: Paweł Bucior, Julia Witek\n",
    "description: Frontend do modelowania biznesowego\n",
    "params:\n",
    "    file_name:\n",
    "        input: file\n",
    "        label: Załaduj plik z danymi\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BPMN\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "!pip install opyenxes\n",
    "!apt install libgraphviz-dev\n",
    "# !apt install graphviz graphviz-dev\n",
    "!pip install pygraphviz\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KY33PjI7Ov-g",
    "outputId": "05c1f130-eb81-423d-80b5-bc4f91b8202f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting opyenxes\n",
      "  Downloading opyenxes-0.3.0.tar.gz (94 kB)\n",
      "\u001B[?25l\r\u001B[K     |███▌                            | 10 kB 17.4 MB/s eta 0:00:01\r\u001B[K     |███████                         | 20 kB 20.5 MB/s eta 0:00:01\r\u001B[K     |██████████▍                     | 30 kB 22.3 MB/s eta 0:00:01\r\u001B[K     |█████████████▉                  | 40 kB 22.8 MB/s eta 0:00:01\r\u001B[K     |█████████████████▎              | 51 kB 12.0 MB/s eta 0:00:01\r\u001B[K     |████████████████████▊           | 61 kB 13.9 MB/s eta 0:00:01\r\u001B[K     |████████████████████████▏       | 71 kB 13.0 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▋    | 81 kB 12.7 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████ | 92 kB 13.8 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 94 kB 2.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from opyenxes) (7.1.2)\n",
      "Building wheels for collected packages: opyenxes\n",
      "  Building wheel for opyenxes (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for opyenxes: filename=opyenxes-0.3.0-py2.py3-none-any.whl size=79230 sha256=a06abb1cfcd19b064b5c4712e95c14018b845a2b96a7d3d7046670b652538447\n",
      "  Stored in directory: /root/.cache/pip/wheels/b2/0b/80/cb6b1a80882eff1d3707d9b30ca5febe120d7fa0120e38e69b\n",
      "Successfully built opyenxes\n",
      "Installing collected packages: opyenxes\n",
      "Successfully installed opyenxes-0.3.0\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  libnvidia-common-460 nsight-compute-2020.2.0\n",
      "Use 'apt autoremove' to remove them.\n",
      "The following additional packages will be installed:\n",
      "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
      "  libgvc6-plugins-gtk libxdot4\n",
      "Suggested packages:\n",
      "  gvfs\n",
      "The following NEW packages will be installed:\n",
      "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libgvc6-plugins-gtk libxdot4\n",
      "0 upgraded, 8 newly installed, 0 to remove and 42 not upgraded.\n",
      "Need to get 2,120 kB of archives.\n",
      "After this operation, 7,128 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libxdot4 amd64 2.40.1-2 [15.7 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6-plugins-gtk amd64 2.40.1-2 [18.2 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgraphviz-dev amd64 2.40.1-2 [57.3 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
      "Fetched 2,120 kB in 1s (2,573 kB/s)\n",
      "Selecting previously unselected package libgtk2.0-common.\n",
      "(Reading database ... 155202 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
      "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-0:amd64.\n",
      "Preparing to unpack .../1-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail18:amd64.\n",
      "Preparing to unpack .../2-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail-common:amd64.\n",
      "Preparing to unpack .../3-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libxdot4.\n",
      "Preparing to unpack .../4-libxdot4_2.40.1-2_amd64.deb ...\n",
      "Unpacking libxdot4 (2.40.1-2) ...\n",
      "Selecting previously unselected package libgvc6-plugins-gtk.\n",
      "Preparing to unpack .../5-libgvc6-plugins-gtk_2.40.1-2_amd64.deb ...\n",
      "Unpacking libgvc6-plugins-gtk (2.40.1-2) ...\n",
      "Selecting previously unselected package libgraphviz-dev.\n",
      "Preparing to unpack .../6-libgraphviz-dev_2.40.1-2_amd64.deb ...\n",
      "Unpacking libgraphviz-dev (2.40.1-2) ...\n",
      "Selecting previously unselected package libgtk2.0-bin.\n",
      "Preparing to unpack .../7-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Setting up libxdot4 (2.40.1-2) ...\n",
      "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libgvc6-plugins-gtk (2.40.1-2) ...\n",
      "Setting up libgraphviz-dev (2.40.1-2) ...\n",
      "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Collecting pygraphviz\n",
      "  Downloading pygraphviz-1.7.zip (118 kB)\n",
      "\u001B[K     |████████████████████████████████| 118 kB 24.6 MB/s \n",
      "\u001B[?25hBuilding wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pygraphviz: filename=pygraphviz-1.7-cp37-cp37m-linux_x86_64.whl size=165749 sha256=e628336531bcaaecd1a045358377e33406e3d3e7b8ac09e2eba0f3d3010df3c5\n",
      "  Stored in directory: /root/.cache/pip/wheels/8c/bc/0c/ac35392b72556e75107ff610cb31b313e8471918a6d280e34c\n",
      "Successfully built pygraphviz\n",
      "Installing collected packages: pygraphviz\n",
      "Successfully installed pygraphviz-1.7\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1K-DMpoLgqr4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "file_name='example.csv'"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Set\n",
    "from IPython.display import Image, display"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string, fuzzy=False):\n",
    "    try:\n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_csv(df):\n",
    "    case_id = ''\n",
    "    start_time = ''\n",
    "    activity = ''\n",
    "\n",
    "    if (case_id == '' or start_time == '' or activity == ''):\n",
    "      for col in df.columns:\n",
    "        if(len(df.columns)<3):\n",
    "          print(\"Provided file cannot be used as an event log\")\n",
    "\n",
    "        if(len(df.columns)==3):\n",
    "          if (df[col].dtypes == 'int64'):\n",
    "            case_id = col\n",
    "          elif (is_date(df.loc[0, col]) == True):\n",
    "            start_time = col\n",
    "          elif (df[col].dtypes != 'int64' and is_date(df.loc[0, col]) == False):\n",
    "            activity = col\n",
    "          else:\n",
    "            case_id = input(\"Enter the name of id column: \")\n",
    "            activity = input(\"Enter the name of activity column: \")\n",
    "            start_time = input(\"Enter the name of timestamp column: \")\n",
    "\n",
    "        if(len(df.columns)>3):\n",
    "          if (df[col].dtypes == 'int64'):\n",
    "            case_id = col\n",
    "          elif (is_date(df.loc[0, col]) == True):\n",
    "            start_time = col\n",
    "            activity = input(\"Enter the name of activity column: \")\n",
    "          else:\n",
    "            case_id = input(\"Enter the name of id column: \")\n",
    "            activity = input(\"Enter the name of activity column: \")\n",
    "            start_time = input(\"Enter the name of timestamp column: \")\n",
    "\n",
    "    print(start_time)\n",
    "    print(case_id)\n",
    "    print(activity)\n",
    "    dfs = (df\n",
    "    .sort_values(by=[case_id, start_time])\n",
    "    .groupby([case_id])\n",
    "    .agg({activity: ' '.join}))\n",
    "    events = dfs.Activity.tolist()\n",
    "    events_csv = []\n",
    "    for line in events:\n",
    "        events_csv.append(line.split())\n",
    "\n",
    "    return events_csv\n",
    "\n",
    "\n",
    "clear_output(wait=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from opyenxes.data_in.XUniversalParser import XUniversalParser\n",
    "import pandas as pd\n",
    "\n",
    "f = open(file_name, \"r\")\n",
    "if f.name.endswith('.csv'):\n",
    "  print('csv')\n",
    "  df = pd.read_csv(file_name)\n",
    "  events = process_csv(df)\n",
    "elif f.name.endswith('.xes'):\n",
    "  print('xes')\n",
    "  with open(file_name) as log_file:\n",
    "    # parse the log\n",
    "    log = XUniversalParser().parse(log_file)[0]\n",
    "    event = log[0][0]\n",
    "    event.get_attributes()\n",
    "    events_xes = []\n",
    "    for trace in log:\n",
    "        events_w = []\n",
    "        for event in trace[0::]:\n",
    "            name = event.get_attributes()['Activity'].get_value()\n",
    "            events_w.append(name)\n",
    "        events_xes.append(events_w)\n",
    "    events = events_xes\n",
    "else:\n",
    "  print('Nie rozpoznano pliku')\n",
    "\n",
    "\n",
    "clear_output(wait=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_start_set_events(events_tab):\n",
    "  start_set_events = set()\n",
    "  for line in events_tab:\n",
    "    start_set_events.add(line[0])\n",
    "\n",
    "  return start_set_events\n",
    "\n",
    "\n",
    "def get_end_set_events(events_tab):\n",
    "  end_set_events = set()\n",
    "  for line in events_tab:\n",
    "    end_set_events.add(line[len(line)-1])\n",
    "\n",
    "  return end_set_events\n",
    "\n",
    "def get_direct_successtion(events):\n",
    "  direct_new = {}\n",
    "  unique_elements = []\n",
    "  for r in events:\n",
    "   for c in r:\n",
    "      if c not in unique_elements:\n",
    "        unique_elements.append(c)\n",
    "  unique_elements = sorted(unique_elements)\n",
    "  for ue in unique_elements:\n",
    "    relations = set()\n",
    "    for r in events:\n",
    "      for index, c in enumerate(r):\n",
    "        if c == ue and int(len(r)) > int(index+1):\n",
    "          relations.add(r[index+1])\n",
    "    if len(relations) > 0:\n",
    "      direct_new[ue] = relations\n",
    "    else:\n",
    "      direct_new[ue] = {}\n",
    "\n",
    "  return direct_new\n",
    "\n",
    "\n",
    "def get_causality(direct_succession) -> Dict[str, Set[str]]:\n",
    "    causality = defaultdict(set)\n",
    "    for ev_cause, events in direct_succession.items():\n",
    "        for event in events:\n",
    "            if ev_cause not in direct_succession.get(event, set()):\n",
    "                causality[ev_cause].add(event)\n",
    "\n",
    "    return dict(causality)\n",
    "\n",
    "\n",
    "def get_potential_parallelism(direct_succession) -> Dict[str, Set[str]]:\n",
    "  potential_parallelism = []\n",
    "  for ev_cause, events in direct_succession.items():\n",
    "    tmp = []\n",
    "    for event in events:\n",
    "      if ev_cause in direct_succession.get(event, set()):\n",
    "        if ev_cause not in tmp:\n",
    "          tmp.append(ev_cause)\n",
    "        tmp.append(event)\n",
    "\n",
    "    if len(tmp) > 0:\n",
    "      potential_parallelism.append(tuple(tmp))\n",
    "  if len(potential_parallelism) > 0:\n",
    "    potential_parallelism.append(tuple(sorted(potential_parallelism[0])))\n",
    "\n",
    "  return potential_parallelism\n",
    "\n",
    "\n",
    "def get_inv_causality(causality) -> Dict[str, Set[str]]:\n",
    "    inv_causality = defaultdict(set)\n",
    "    for key, values in causality.items():\n",
    "        for value in values:\n",
    "          inv_causality[value].add(key)\n",
    "\n",
    "    return {k: v for k, v in inv_causality.items() if len(v) > 1}\n",
    "\n",
    "\n",
    "clear_output(wait=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyGraph(pgv.AGraph):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        super(MyGraph, self).__init__(strict=False, directed=True, *args)\n",
    "        self.graph_attr['rankdir'] = 'LR'\n",
    "        self.node_attr['shape'] = 'Mrecord'\n",
    "        self.graph_attr['splines'] = 'ortho'\n",
    "        self.graph_attr['nodesep'] = '0.8'\n",
    "        self.edge_attr.update(penwidth='2')\n",
    "\n",
    "    def add_event(self, name):\n",
    "        super(MyGraph, self).add_node(name, shape=\"circle\", label=\"\")\n",
    "\n",
    "    def get_node(self,name):\n",
    "        return super(MyGraph, self).get_node(name)\n",
    "\n",
    "    def get_edges(self):\n",
    "        return super(MyGraph, self).edges()\n",
    "\n",
    "    def add_end_event(self, name):\n",
    "        super(MyGraph, self).add_node(name, shape=\"circle\", label=\"\",penwidth='3')\n",
    "\n",
    "    def add_and_gateway(self, *args):\n",
    "        super(MyGraph, self).add_node(*args, shape=\"diamond\",\n",
    "                                  width=\".7\",height=\".7\",\n",
    "                                  fixedsize=\"true\",\n",
    "                                  fontsize=\"40\",label=\"+\")\n",
    "\n",
    "    def add_xor_gateway(self, *args, **kwargs):\n",
    "        super(MyGraph, self).add_node(*args, shape=\"diamond\",\n",
    "                                  width=\".7\",height=\".7\",\n",
    "                                  fixedsize=\"true\",\n",
    "                                  fontsize=\"40\",label=\"×\")\n",
    "    def add_xor_inclusive_gateway(self, *args, **kwargs):\n",
    "        super(MyGraph, self).add_node(*args, shape=\"diamond\",\n",
    "                                  width=\".7\",height=\".7\",\n",
    "                                  fixedsize=\"true\",\n",
    "                                  fontsize=\"40\",label=\"o\")\n",
    "\n",
    "    def add_event_gateway(self, source, targets, *args):\n",
    "        gateway = 'EVENTs '+str(source)+'->'+str(targets)\n",
    "        self.add_xor_inclusive_gateway(gateway,*args)\n",
    "        super(MyGraph, self).add_edge(source, gateway)\n",
    "        for target in targets:\n",
    "            super(MyGraph, self).add_edge(gateway, target)\n",
    "\n",
    "    def add_and_split_gateway(self, source, targets, *args):\n",
    "        gateway = 'ANDs '+str(source)+'->'+str(targets)\n",
    "        self.add_and_gateway(gateway,*args)\n",
    "        super(MyGraph, self).add_edge(source, gateway)\n",
    "        for target in targets:\n",
    "            super(MyGraph, self).add_edge(gateway, target)\n",
    "\n",
    "    def add_xor_split_gateway(self, source, targets, *args):\n",
    "        gateway = 'XORs '+str(source)+'->'+str(targets)\n",
    "        self.add_xor_gateway(gateway, *args)\n",
    "        super(MyGraph, self).add_edge(source, gateway)\n",
    "        for target in targets:\n",
    "            super(MyGraph, self).add_edge(gateway, target)\n",
    "\n",
    "    def add_event_merge_gateway(self, sources, target, *args):\n",
    "        gateway = 'EVENTm '+str(sources)+'->'+str(target)\n",
    "        self.add_xor_inclusive_gateway(gateway,*args)\n",
    "        super(MyGraph, self).add_edge(gateway,target)\n",
    "        for source in sources:\n",
    "            super(MyGraph, self).add_edge(source, gateway)\n",
    "\n",
    "    def add_and_merge_gateway(self, sources, target, *args):\n",
    "        gateway = 'ANDm '+str(sources)+'->'+str(target)\n",
    "        self.add_and_gateway(gateway,*args)\n",
    "        super(MyGraph, self).add_edge(gateway,target)\n",
    "        for source in sources:\n",
    "            super(MyGraph, self).add_edge(source, gateway)\n",
    "\n",
    "    def add_xor_merge_gateway(self, sources, target, *args):\n",
    "        gateway = 'XORm '+str(sources)+'->'+str(target)\n",
    "        self.add_xor_gateway(gateway, *args)\n",
    "        super(MyGraph, self).add_edge(gateway,target)\n",
    "        for source in sources:\n",
    "            super(MyGraph, self).add_edge(source, gateway)\n",
    "\n",
    "    def add_xor_to_and_gateway(self, sources, targets, *args):\n",
    "        gateway_xor = 'XORm '+str(sources)+'->'+str(targets)\n",
    "        gateway_and = 'ANDs '+str(sources)+'->'+str(targets)\n",
    "        self.add_xor_gateway(gateway_xor, *args)\n",
    "        self.add_and_gateway(gateway_and, *args)\n",
    "        super(MyGraph, self).add_edge(gateway_xor,gateway_and)\n",
    "        for source in sources:\n",
    "            super(MyGraph, self).add_edge(source, gateway_xor)\n",
    "        for target in targets:\n",
    "            super(MyGraph, self).add_edge(gateway_and, target)\n",
    "\n",
    "\n",
    "clear_output(wait=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def draw_graph(events):\n",
    "\n",
    "  # events_tab = []\n",
    "  # for line in events.splitlines():\n",
    "  #     events_tab.append(line.split())\n",
    "\n",
    "  events_tab = events\n",
    "  start_set_events = get_start_set_events(events_tab)\n",
    "  end_set_events = get_end_set_events(events_tab)\n",
    "  direct_succession = get_direct_successtion(events_tab)\n",
    "  parallel_events = get_potential_parallelism(direct_succession)\n",
    "  causality = get_causality(direct_succession)\n",
    "  inv_causality = get_inv_causality(causality)\n",
    "\n",
    "  G = MyGraph()\n",
    "\n",
    "  # adding start event\n",
    "  G.add_event(\"start\")\n",
    "  if len(start_set_events) > 1:\n",
    "      if tuple(start_set_events) in sorted(parallel_events):\n",
    "          G.add_and_split_gateway(\"start\",start_set_events)\n",
    "\n",
    "      else:\n",
    "          G.add_xor_split_gateway(\"start\",start_set_events)\n",
    "  else:\n",
    "      G.add_edge(\"start\",list(start_set_events)[0])\n",
    "\n",
    "  # adding split gateways based on causality\n",
    "  for event in causality:\n",
    "      if len(causality[event]) > 1 and tuple(causality[event]) != tuple(inv_causality.keys()):\n",
    "          if tuple(causality[event]) in parallel_events:\n",
    "\n",
    "              to_check = list(causality[event])\n",
    "              is_event = False\n",
    "              for eventeee in events_tab:\n",
    "                if len(to_check) != len(list(set(sorted(to_check)).intersection(sorted(set(eventeee))))):\n",
    "                  is_event = True\n",
    "\n",
    "              if is_event:\n",
    "                G.add_event_gateway(event,causality[event])\n",
    "              else:\n",
    "                G.add_and_split_gateway(event,causality[event])\n",
    "          else:\n",
    "              G.add_xor_split_gateway(event,causality[event])\n",
    "\n",
    "  # adding merge gateways based on inverted causality\n",
    "  for event in inv_causality:\n",
    "      if len(inv_causality[event]) > 1 and tuple(sorted(inv_causality[event])) != tuple(sorted(causality.keys())):\n",
    "          if tuple(inv_causality[event]) in parallel_events:\n",
    "              to_check = list(inv_causality[event])\n",
    "              is_event = False\n",
    "              for eventeee in events_tab:\n",
    "                if len(to_check) != len(list(set(sorted(to_check)).intersection(sorted(set(eventeee))))):\n",
    "                  is_event = True\n",
    "\n",
    "              if is_event:\n",
    "                G.add_event_merge_gateway(inv_causality[event],event)\n",
    "              else:\n",
    "                G.add_and_merge_gateway(inv_causality[event],event)\n",
    "\n",
    "          else:\n",
    "              G.add_xor_merge_gateway(inv_causality[event],event)\n",
    "      elif len(inv_causality[event]) == 1:\n",
    "          source = list(inv_causality[event])[0]\n",
    "          G.add_edge(source,event)\n",
    "\n",
    "  xor_merge_gateways = set()\n",
    "  for event in inv_causality:\n",
    "    if (len(inv_causality[event]) > 1 and tuple(sorted(inv_causality[event])) == tuple(sorted(causality.keys()))):\n",
    "      xor_merge_gateways.add(tuple(sorted(inv_causality[event])))\n",
    "\n",
    "  # print(xor_merge_gateways)\n",
    "  for create_gateway_event in xor_merge_gateways:\n",
    "     G.add_xor_to_and_gateway(inv_causality[event],tuple(inv_causality.keys()))\n",
    "\n",
    "  end_to_delete = False\n",
    "  for end_event in end_set_events:\n",
    "      for start_event in start_set_events:\n",
    "        try:\n",
    "          if tuple(causality[end_event]) == tuple(start_event):\n",
    "            G.add_xor_split_gateway(end_event, (start_event,\"end\"))\n",
    "            end_to_delete = True\n",
    "        except:\n",
    "          print('')\n",
    "\n",
    "  # adding end event\n",
    "  G.add_end_event(\"end\")\n",
    "  if len(end_set_events) > 1 and end_to_delete == False:\n",
    "      if tuple(end_set_events) in parallel_events:\n",
    "          G.add_and_merge_gateway(end_set_events,\"end\")\n",
    "      else:\n",
    "          G.add_xor_merge_gateway(end_set_events,\"end\")\n",
    "  elif end_to_delete == False:\n",
    "      G.add_edge(list(end_set_events)[0],\"end\")\n",
    "\n",
    "  add_edges_list = []\n",
    "  for sucession in direct_succession:\n",
    "    found_count = 0\n",
    "    for test in direct_succession:\n",
    "      if test != sucession:\n",
    "        if sucession in direct_succession[test]:\n",
    "          found_count = found_count + 1\n",
    "    if(found_count == len(direct_succession) -1):\n",
    "      add_edges_list.append(sucession);\n",
    "\n",
    "  for single_causality in causality:\n",
    "    to_check = causality[single_causality]\n",
    "    found_count = 1\n",
    "    for test in causality:\n",
    "      if test != single_causality:\n",
    "        if to_check == causality[test]:\n",
    "          found_count = found_count + 1\n",
    "    if len(to_check) == 1 and found_count == 1 and list(to_check)[0] in add_edges_list:\n",
    "      G.add_edge(single_causality,list(to_check)[0])\n",
    "\n",
    "  G.draw('simple_process_model.png', prog='dot')\n",
    "  display(Image('simple_process_model.png'))\n",
    "\n",
    "clear_output(wait=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "draw_graph(events)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}